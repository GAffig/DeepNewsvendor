{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def csv_to_npz():\n",
    "    test_data = np.genfromtxt('test_Ice.csv' ,dtype=float, delimiter=',',skip_header=0)\n",
    "    train_data = np.genfromtxt('train_Ice.csv' ,dtype=float, delimiter=',',skip_header=0)\n",
    "    \n",
    "    test_x = test_data[1:, 1:-1]\n",
    "    train_x = train_data[1:, 1:-1]\n",
    "\n",
    "    test_y = test_data[1:, -1]\n",
    "    train_y = train_data[1:, -1]\n",
    "\n",
    "    np.savez_compressed('test.npz', X=test_x, Y=test_y)\n",
    "    np.savez_compressed('train.npz', X=train_x, Y=train_y)\n",
    "\n",
    "def npz_check():\n",
    "    data = np.load('train.npz')\n",
    "    print(data['X'].shape)\n",
    "    return data\n",
    "\n",
    "csv_to_npz()\n",
    "npz_check()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import params\n",
    "\n",
    "from train_utils import *\n",
    "\n",
    "model_type = 'simple_fc'  # 'att_context'\n",
    "id = 'simple_fc'\n",
    "\n",
    "# Set hyperparams:\n",
    "missing = False\n",
    "num_epochs = params.NUM_EPOCHS\n",
    "batch_size = params.BATCH_SIZE\n",
    "anneal_factor = params.ANNEALING_FACTOR\n",
    "patience = params.PATIENCE\n",
    "\n",
    "seed = 0\n",
    "\n",
    "torch.cuda.synchronize() # comment\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# set random seeds\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Other imports now\n",
    "from data_utils import SalesDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "TRAIN = 'train.npz'\n",
    "TEST = 'test.npz'\n",
    "\n",
    "train_data = SalesDataset(TRAIN, randomize = False)\n",
    "test_data = SalesDataset(TEST, randomize = False)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size, shuffle = True)\n",
    "val_loader = test_loader\n",
    "\n",
    "#------------------#\n",
    "# Model Definition #\n",
    "#------------------#\n",
    "\n",
    "from hyperband import random_nn_params\n",
    "from model import DeepVendorSimple\n",
    "from loss_function import EuclideanLoss, CostFunction\n",
    "\n",
    "best_overall_model = None\n",
    "best_overall_cost = 100000.\n",
    "best_model_idx = 0\n",
    "\n",
    "\n",
    "for model_idx in tqdm(range(params.NUM_MODELS)):\n",
    "\n",
    "    hidden_layers, n_nodes, lr, weight_decay = random_nn_params()\n",
    "\n",
    "    model = DeepVendorSimple(n_hidden = hidden_layers, n_nodes = n_nodes)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    #torch.cuda.memory_summary()\n",
    "    #device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    device = torch.device('cpu')\n",
    "    print(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay)\n",
    "\n",
    "    criterion = EuclideanLoss(params.SHORTAGE_COST, params.HOLDING_COST)\n",
    "    test_criterion = CostFunction(params.SHORTAGE_COST, params.HOLDING_COST)\n",
    "\n",
    "    writer_path = os.path.join(id+'_idx_'+str(model_idx))\n",
    "    writer = SummaryWriter(writer_path)\n",
    "\n",
    "    best_model = None\n",
    "    best_val_loss = 100000.0\n",
    "\n",
    "    try:\n",
    "        early_stopping = EarlyStopping(patience=patience, verbose=False)\n",
    "\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Train model\n",
    "            loss = discriminative_trainer(\n",
    "                model=model,\n",
    "                data_loader=train_loader,\n",
    "                optimizer=optimizer,\n",
    "                criterion=criterion)\n",
    "            print(f'epoch: {epoch}, loss: {loss}')\n",
    "\n",
    "            # log in tensorboard\n",
    "            writer.add_scalar('Training/Prediction Loss', loss, epoch)\n",
    "\n",
    "            # Eval model\n",
    "            loss = discriminative_evaluate(model, val_loader, test_criterion)\n",
    "            writer.add_scalar('Validation/Prediction Cost', loss, epoch)\n",
    "\n",
    "            if loss < best_val_loss:\n",
    "                best_val_loss = loss\n",
    "                best_model = deepcopy(model)\n",
    "\n",
    "            # Anneal LR\n",
    "            early_stopping(loss, model)\n",
    "            if early_stopping.early_stop:  # and epoch > params.MIN_EPOCH:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('Stopping training. Now testing')\n",
    "\n",
    "    # Test the model\n",
    "    model = best_model\n",
    "    torch.cuda.empty_cache()\n",
    "    loss= discriminative_evaluate(model, test_loader, test_criterion)\n",
    "    print('Test Prediction Cost: ', loss)\n",
    "\n",
    "    if loss < best_overall_cost:\n",
    "        best_overall_model = deepcopy(model)\n",
    "        best_overall_cost = loss\n",
    "        best_model_idx = model_idx\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join('best_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
